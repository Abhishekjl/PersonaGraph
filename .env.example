# PersonaGraph Environment Configuration
# Copy this file to .env and fill in your actual values

# ============================================
# APPLICATION SETTINGS
# ============================================
APP_NAME=PersonaGraph
APP_VERSION=1.0.0
ENVIRONMENT=development  # development, staging, production
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# ============================================
# MILVUS VECTOR DATABASE
# ============================================
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_USER=
MILVUS_PASSWORD=
MILVUS_COLLECTION_NAME=persona_graph

# ============================================
# REDIS CACHE
# ============================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_MAX_CONNECTIONS=50
CACHE_TTL=3600  # Prompt cache TTL in seconds (1 hour)

# ============================================
# EMBEDDING MODEL
# ============================================
EMBED_MODEL=all-MiniLM-L6-v2  # Options: all-MiniLM-L6-v2, all-mpnet-base-v2, instructor-xl
EMBED_DIMENSION=384  # Must match model: 384 for MiniLM, 768 for mpnet, 1536 for OpenAI

# ============================================
# LLM PROVIDER (OpenAI / Azure / vLLM)
# ============================================
LLM_PROVIDER=openai  # openai, azure, vllm, anthropic
LLM_API_KEY=sk-your-openai-api-key-here
LLM_MODEL=gpt-4-turbo-preview  # gpt-4-turbo-preview, gpt-3.5-turbo, claude-3-opus
LLM_MAX_TOKENS=512
LLM_TEMPERATURE=0.7

# For Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_DEPLOYMENT_NAME=gpt-4

# For self-hosted vLLM
VLLM_ENDPOINT=http://localhost:8001/v1
VLLM_MODEL=meta-llama/Llama-2-7b-chat-hf

# ============================================
# AUTHENTICATION & SECURITY
# ============================================
JWT_SECRET=your-super-secret-jwt-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24
ALLOWED_ORIGINS=http://localhost:3000,https://yourdomain.com

# ============================================
# EXTERNAL API KEYS
# ============================================

# ZoomInfo - Firmographic Data
ZOOMINFO_API_KEY=your-zoominfo-api-key-here
ZOOMINFO_BASE_URL=https://api.zoominfo.com/v1
ZOOMINFO_RATE_LIMIT=100  # requests per minute

# Demandbase - Intent Data
DEMANDBASE_API_KEY=your-demandbase-api-key-here
DEMANDBASE_BASE_URL=https://api.demandbase.com/api/v3
DEMANDBASE_RATE_LIMIT=60

# People Data Labs - Contact Data
PDL_API_KEY=your-pdl-api-key-here
PDL_BASE_URL=https://api.peopledatalabs.com/v5
PDL_RATE_LIMIT=100

# ============================================
# PERFORMANCE & OPTIMIZATION
# ============================================

# Threadpool Settings
THREADPOOL_MAX_WORKERS=8

# API Rate Limiting
API_RATE_LIMIT_PER_MINUTE=60
API_RATE_LIMIT_BURST=10

# Batch Processing
BATCH_SIZE=10
BATCH_TIMEOUT_SECONDS=5

# Circuit Breaker
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT_SECONDS=60

# ============================================
# MONITORING & OBSERVABILITY
# ============================================
ENABLE_METRICS=true
PROMETHEUS_PORT=9090
METRICS_ENDPOINT=/metrics

# Sentry Error Tracking (Optional)
SENTRY_DSN=
SENTRY_ENVIRONMENT=development
SENTRY_TRACES_SAMPLE_RATE=0.1

# ============================================
# KUBERNETES / CLOUD DEPLOYMENT
# ============================================

# Service Configuration
SERVICE_HOST=0.0.0.0
SERVICE_PORT=8000
WORKERS=4  # Uvicorn worker processes

# Health Check
HEALTH_CHECK_INTERVAL=30
HEALTH_CHECK_TIMEOUT=10

# Auto-scaling Thresholds
MIN_REPLICAS=2
MAX_REPLICAS=10
CPU_TARGET_UTILIZATION=70
MEMORY_TARGET_UTILIZATION=80

# ============================================
# DATABASE BACKUP & PERSISTENCE
# ============================================
BACKUP_ENABLED=false
BACKUP_SCHEDULE=0 2 * * *  # Daily at 2 AM
BACKUP_RETENTION_DAYS=7
BACKUP_S3_BUCKET=

# ============================================
# FEATURE FLAGS
# ============================================
ENABLE_PROMPT_CACHING=true
ENABLE_FUNCTION_CALLING=true
ENABLE_BATCH_INFERENCE=false  # Enable when using vLLM
ENABLE_MULTI_TENANT_PARTITIONS=true
ENABLE_RATE_LIMITING=true
ENABLE_CIRCUIT_BREAKER=true

# ============================================
# DEVELOPMENT / DEBUG
# ============================================
DEBUG=false
RELOAD=false  # Auto-reload on code changes (development only)
MOCK_EXTERNAL_APIS=false  # Use mock data instead of real API calls
